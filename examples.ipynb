{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# load the API key from env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from functions import get_llm_response\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "\n",
    "print(get_llm_response(client, model, messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using json response\n",
    "\n",
    "Useful when doing classification or connecting LLM output to deterministic functions.\n",
    "\n",
    "You must at least mention \"json\" in the system prompt.\n",
    "\n",
    "More info: https://platform.openai.com/docs/guides/structured-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"capital\": \"Paris\",\n",
      "  \"country\": \"France\",\n",
      "  \"continent\": \"Europe\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from functions import get_llm_response_in_json\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You must return a json object with the following keys: 'capital', 'country', 'continent'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    "\n",
    "print(get_llm_response_in_json(client, model, messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using images\n",
    "\n",
    "You can either use a url of a public image or first encode the image and send it in the same manner. \n",
    "\n",
    "More info: https://platform.openai.com/docs/guides/vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a person giving a thumbs-up gesture. There is a computer monitor visible on the right side of the image. Additionally, there is a signature or text that reads \"Brent Rambo\" at the bottom of the image.\n"
     ]
    }
   ],
   "source": [
    "from functions import encode_image\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"data/thumbs up.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "\n",
    "messages=[\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"What is in this image?\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "        \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        },\n",
    "    },\n",
    "    ],\n",
    "}\n",
    "]\n",
    "\n",
    "# Now you can use these messages with your LLM client\n",
    "print(get_llm_response(client, model, messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "Beyond generating text content, you can provide GPT with your own python functions and instruct it to use them when appropriate. GPT will provide all the variables for the function based on it's best judgement. \n",
    "\n",
    "More info: https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36760\n"
     ]
    }
   ],
   "source": [
    "from functions import function_to_schema, get_llm_response_with_functions\n",
    "import json\n",
    "\n",
    "# Define your functions with a docstring and a return type\n",
    "def print_string(s: str) -> None:\n",
    "    \"\"\"\n",
    "    Print a string\n",
    "    \"\"\"\n",
    "    print(s)\n",
    "\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two numbers\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "# create a map of function names to functions\n",
    "tool_map = {\n",
    "    \"print_string\": print_string,\n",
    "    \"add_two_numbers\": add_two_numbers\n",
    "}\n",
    "\n",
    "# Transform the function into GPT digestible schema\n",
    "tool_schemas = [function_to_schema(print_string),\n",
    "                function_to_schema(add_two_numbers)]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You must use provided functions when appropriate.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 19870 + 16890?\"}]\n",
    "\n",
    "response = get_llm_response_with_functions(client, model, messages, tool_schemas)\n",
    "\n",
    "# tool requesting message has to precede the function result message \n",
    "# if you want to send the request again in a loop\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        tool_response = tool_map[function_name](**arguments)\n",
    "        messages.append({\"role\": \"tool\", \"content\": tool_response})\n",
    "        print(tool_response)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
